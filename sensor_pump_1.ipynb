{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Maintanane prediction - pump sensor data** <br>\n",
    "Link to Kaggle: https://www.kaggle.com/nphantawee/pump-sensor-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I Classification problem** - accident within a period of time <br>\n",
    "**II Regression problem** - RUL - Remaining Useful Time estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** <br>\n",
    "Look through data, prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_raw = pd.read_csv(r'D:\\PROJEKTY\\pump_sensor\\sensor.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop sensor_15 column - only NaN value\n",
    "try:\n",
    "    import_raw.drop(['sensor_15'], axis=1, inplace=True)\n",
    "except KeyError as e:\n",
    "    print(\"Column does not exist:  \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NORMAL', 'BROKEN', 'RECOVERING'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for different machine statuses\n",
    "import_raw['machine_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NORMAL        205836\n",
       "RECOVERING     14477\n",
       "BROKEN             7\n",
       "Name: machine_status, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_raw.machine_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_missing = import_raw.isna()\n",
    "import_data_missing_num = import_data_missing.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_missing_percentage = ((import_data_missing_num / len(import_raw))*100).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.633261</td>\n",
       "      <td>0.167484</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>2.177741</td>\n",
       "      <td>2.474129</td>\n",
       "      <td>2.317992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>34.956881</td>\n",
       "      <td>6.982117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "0        0.0   4.633261   0.167484   0.008624   0.008624   0.008624   \n",
       "\n",
       "   sensor_05  sensor_06  sensor_07  sensor_08  ...  sensor_43  sensor_44  \\\n",
       "0   0.008624   2.177741   2.474129   2.317992  ...   0.012255   0.012255   \n",
       "\n",
       "   sensor_45  sensor_46  sensor_47  sensor_48  sensor_49  sensor_50  \\\n",
       "0   0.012255   0.012255   0.012255   0.012255   0.012255  34.956881   \n",
       "\n",
       "   sensor_51  machine_status  \n",
       "0   6.982117             0.0  \n",
       "\n",
       "[1 rows x 53 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_data_missing_percentage.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~35% of missing in sensor_50\n",
    "sensor_50 = import_raw[['sensor_50']]\n",
    "sensor_50.fillna(value={'sensor_50':'2000'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after changing NA to some outstanding value, I decide to remove this variable\n",
    "# plt.figure(figsize=(20,5))\n",
    "# plt.scatter(sensor_50.index, sensor_50.sensor_50, s=0.2, c='r', marker='x')\n",
    "# plt.xlabel('index')\n",
    "# plt.ylabel('sensor_50')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop sensor_15 column - only NaN value\n",
    "try:\n",
    "    import_raw.drop(['sensor_50'], axis=1, inplace=True)\n",
    "except KeyError as e:\n",
    "    print(\"Column does not exist:  \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sensor_data(sensor_number, import_raw):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    sensor_num = 'sensor_' + str(sensor_number)\n",
    "    plt.scatter(import_raw.index, import_raw[[sensor_num]], s=0.2, c='r', marker='x')\n",
    "    plt.xlabel('index')\n",
    "    plt.ylabel(sensor_num)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_sensor_data('01', import_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check how different states ('NORMAL', 'BROKEN', 'RECOVERING') occur over time\n",
    "# Replace string with numerical representation\n",
    "# Normal=1, Broken=2, Recovering=3\n",
    "machine_status = import_raw[['machine_status']]\n",
    "machine_status.loc[machine_status['machine_status'] == 'NORMAL'] = 1\n",
    "machine_status.loc[machine_status['machine_status'] == 'BROKEN'] = 2\n",
    "machine_status.loc[machine_status['machine_status'] == 'RECOVERING'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,5))\n",
    "# plt.scatter(machine_status.index, machine_status.where(machine_status['machine_status']==1), s=0.1, c='b', marker='x')\n",
    "# plt.scatter(machine_status.index, machine_status.where(machine_status['machine_status']==2), s=25, c='r', marker='x')\n",
    "# plt.scatter(machine_status.index, machine_status.where(machine_status['machine_status']==3), s=0.1, c='g', marker='x')\n",
    "# plt.xlabel('index')\n",
    "# plt.ylabel('Machine Status')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After looking at sensor values visualisations - it looks at the first sight that 'outsiders' values may be connected with breakdown in machines work\n",
    "# I've decided to replace missing values with AKIMA interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df_akima = import_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df_akima.interpolate(method='akima', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_num = '51' \n",
    "# plt.figure(figsize=(20,5))\n",
    "# sensor_num = 'sensor_' + str(sensor_num)\n",
    "# plt.scatter(sensors_df_akima.index, sensors_df_akima[[sensor_num]], s=0.2, c='g', marker='x')\n",
    "# plt.scatter(import_raw.index, import_raw[[sensor_num]], s=0.2, c='r', marker='x')\n",
    "# plt.xlabel('index')\n",
    "# plt.ylabel(sensor_num)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(sensors_df_akima[['machine_status']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df_akima_one_hot = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_BROKEN</th>\n",
       "      <th>x0_NORMAL</th>\n",
       "      <th>x0_RECOVERING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_BROKEN  x0_NORMAL  x0_RECOVERING\n",
       "0        0.0        1.0            0.0\n",
       "1        0.0        1.0            0.0\n",
       "2        0.0        1.0            0.0\n",
       "3        0.0        1.0            0.0\n",
       "4        0.0        1.0            0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_df_akima_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace categorical column with one hot encoded\n",
    "try:\n",
    "    sensors_df_akima.drop(['machine_status'], axis=1, inplace=True)\n",
    "except KeyError as e:\n",
    "    print(\"Column does not exist:  \", str(e))\n",
    "    \n",
    "#inner join tables on index\n",
    "\n",
    "#make sure arrays have the same number of rows\n",
    "if sensors_df_akima.shape[0] == sensors_df_akima_one_hot.shape[0]:\n",
    "    sensors_df_akima = pd.concat([sensors_df_akima, sensors_df_akima_one_hot], axis=1, join='inner')\n",
    "else:\n",
    "    print(\"Different number of rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>x0_BROKEN</th>\n",
       "      <th>x0_NORMAL</th>\n",
       "      <th>x0_RECOVERING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-01 00:01:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-01 00:02:00</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>15.61777</td>\n",
       "      <td>...</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01 00:03:00</td>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.1684</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.1250</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>203.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-01 00:04:00</td>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.4583</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "0  2018-04-01 00:00:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "1  2018-04-01 00:01:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2  2018-04-01 00:02:00   2.444734   47.35243    53.2118  46.397570   638.8889   \n",
       "3  2018-04-01 00:03:00   2.460474   47.09201    53.1684  46.397568   628.1250   \n",
       "4  2018-04-01 00:04:00   2.445718   47.13541    53.2118  46.397568   636.4583   \n",
       "\n",
       "   sensor_05  sensor_06  sensor_07  sensor_08  ...  sensor_44  sensor_45  \\\n",
       "0   76.45975   13.41146   16.13136   15.56713  ...  39.641200   65.68287   \n",
       "1   76.45975   13.41146   16.13136   15.56713  ...  39.641200   65.68287   \n",
       "2   73.54598   13.32465   16.03733   15.61777  ...  39.351852   65.39352   \n",
       "3   76.98898   13.31742   16.24711   15.69734  ...  39.062500   64.81481   \n",
       "4   76.58897   13.35359   16.21094   15.69734  ...  38.773150   65.10416   \n",
       "\n",
       "   sensor_46  sensor_47  sensor_48  sensor_49  sensor_51  x0_BROKEN  \\\n",
       "0   50.92593  38.194440   157.9861   67.70834   201.3889        0.0   \n",
       "1   50.92593  38.194440   157.9861   67.70834   201.3889        0.0   \n",
       "2   51.21528  38.194443   155.9606   67.12963   203.7037        0.0   \n",
       "3   51.21528  38.194440   155.9606   66.84028   203.1250        0.0   \n",
       "4   51.79398  38.773150   158.2755   66.55093   201.3889        0.0   \n",
       "\n",
       "   x0_NORMAL  x0_RECOVERING  \n",
       "0        1.0            0.0  \n",
       "1        1.0            0.0  \n",
       "2        1.0            0.0  \n",
       "3        1.0            0.0  \n",
       "4        1.0            0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_df_akima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's perform some PCA analysis to see the distribution of variance** <br>\n",
    "**Also let's check how existing features imply on the state of machine - Random Forest Classifier** <br>\n",
    "Afterwards some feature engineering will be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_PCA(n_components):\n",
    "    model = PCA(n_components)\n",
    "    model.fit_transform(sensors_df_akima[sensors_df_akima.columns.difference(['timestamp', 'x0_BROKEN', 'x0_NORMAL', 'x0_RECOVERING'])])\n",
    "    \n",
    "    var_ratio = model.explained_variance_ratio_\n",
    "    var_ratio_sum = model.explained_variance_ratio_.cumsum()\n",
    "    print('Explained variance ratio: \\n', var_ratio)\n",
    "    print('Explained variance ratio sum: \\n', var_ratio_sum)\n",
    "    \n",
    "    X = np.arange(1, n_components+1)\n",
    "    plt.scatter(x=X, y=var_ratio, marker='*', c='g')\n",
    "    plt.scatter(x=X, y=var_ratio_sum, marker = 'o', c='r')\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_model = display_PCA(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = sensors_df_akima.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# sns.heatmap(corr, linewidths=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>x0_BROKEN</th>\n",
       "      <th>x0_NORMAL</th>\n",
       "      <th>x0_RECOVERING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-01 00:01:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-01 00:02:00</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>15.61777</td>\n",
       "      <td>...</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01 00:03:00</td>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.1684</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.1250</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>203.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-01 00:04:00</td>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.4583</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "0  2018-04-01 00:00:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "1  2018-04-01 00:01:00   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2  2018-04-01 00:02:00   2.444734   47.35243    53.2118  46.397570   638.8889   \n",
       "3  2018-04-01 00:03:00   2.460474   47.09201    53.1684  46.397568   628.1250   \n",
       "4  2018-04-01 00:04:00   2.445718   47.13541    53.2118  46.397568   636.4583   \n",
       "\n",
       "   sensor_05  sensor_06  sensor_07  sensor_08  ...  sensor_44  sensor_45  \\\n",
       "0   76.45975   13.41146   16.13136   15.56713  ...  39.641200   65.68287   \n",
       "1   76.45975   13.41146   16.13136   15.56713  ...  39.641200   65.68287   \n",
       "2   73.54598   13.32465   16.03733   15.61777  ...  39.351852   65.39352   \n",
       "3   76.98898   13.31742   16.24711   15.69734  ...  39.062500   64.81481   \n",
       "4   76.58897   13.35359   16.21094   15.69734  ...  38.773150   65.10416   \n",
       "\n",
       "   sensor_46  sensor_47  sensor_48  sensor_49  sensor_51  x0_BROKEN  \\\n",
       "0   50.92593  38.194440   157.9861   67.70834   201.3889        0.0   \n",
       "1   50.92593  38.194440   157.9861   67.70834   201.3889        0.0   \n",
       "2   51.21528  38.194443   155.9606   67.12963   203.7037        0.0   \n",
       "3   51.21528  38.194440   155.9606   66.84028   203.1250        0.0   \n",
       "4   51.79398  38.773150   158.2755   66.55093   201.3889        0.0   \n",
       "\n",
       "   x0_NORMAL  x0_RECOVERING  \n",
       "0        1.0            0.0  \n",
       "1        1.0            0.0  \n",
       "2        1.0            0.0  \n",
       "3        1.0            0.0  \n",
       "4        1.0            0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_df_akima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(table, column_name):\n",
    "    table_1 = table[column_name]\n",
    "    grouper = (table_1 != table_1.shift()).cumsum()\n",
    "    return grouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df_akima['normal_time'] = sensors_df_akima.groupby(grouper(sensors_df_akima, 'x0_NORMAL'))['x0_NORMAL'].cumsum()\n",
    "sensors_df_akima['broken_time'] = sensors_df_akima.groupby(grouper(sensors_df_akima, 'x0_BROKEN'))['x0_BROKEN'].cumsum()\n",
    "sensors_df_akima['recovering_time'] = sensors_df_akima.groupby(grouper(sensors_df_akima, 'x0_RECOVERING'))['x0_RECOVERING'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(x=np.arange(start=0, stop=len(sensors_df_akima)),\n",
    "#            y=sensors_df_akima['normal_time'],\n",
    "#            s=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17155     1.0\n",
       "24510     1.0\n",
       "69318     1.0\n",
       "77790     1.0\n",
       "128040    1.0\n",
       "141131    1.0\n",
       "166440    1.0\n",
       "Name: broken_time, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = sensors_df_akima['broken_time'].diff()\n",
    "difference.loc[difference==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data covers: 153 days.\n"
     ]
    }
   ],
   "source": [
    "print('Data covers: ' + str(int(len(sensors_df_akima)/60/24)) + ' days.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole dataset covers 153 days. </br>\n",
    "Lets try to classify, whether pump will brake in the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_broken_flag(df, n):\n",
    "    \"\"\"Add flag to the datasset to indicate that failure will be in [n] days\"\"\"\n",
    "    num_of_periods = n*24*60\n",
    "    col_name = 'fail_in_' + str(n) + '_days'\n",
    "    broken_index = df.loc[df['x0_BROKEN']==1].index\n",
    "    df[col_name] = df['x0_BROKEN']\n",
    "    for i in broken_index:\n",
    "        df.loc[(int(i)-200): i, col_name] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df_akima = add_broken_flag(sensors_df_akima, 1)\n",
    "sensors_df_akima = add_broken_flag(sensors_df_akima, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into train, and test set** </br>\n",
    "Because the data we're dealing with is time-series like, we cannot simply apply random train - test split. </br>\n",
    "This requires split in *time-dependent* manner, so that model is not trained on data that will come in the future. </br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,5))\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# colors = ['b', 'r', 'g']\n",
    "# plot_1 = ax1.scatter(machine_status.index, machine_status.where(machine_status['machine_status']==1), s=0.1, c=colors[0], marker='x')\n",
    "# plot_2 = ax1.scatter(machine_status.index, machine_status.where(machine_status['machine_status']==2), s=25, c=colors[1], marker='x')\n",
    "# plot_3 = ax1.scatter(machine_status.index, machine_status.where(machine_status['machine_status']==3), s=0.1, c=colors[2], marker='x')\n",
    "# ax1.set_xlabel('index')\n",
    "# ax1.set_ylabel('Machine Status')\n",
    "\n",
    "# ax1.legend((plot_1, plot_2, plot_3),\n",
    "#            ('Recovery', 'Broken', 'Normal'),\n",
    "#            scatterpoints=5,\n",
    "#            loc='top right',\n",
    "#            ncol=1,\n",
    "#            fontsize=16)\n",
    "\n",
    "# ax2 = ax1.twiny()\n",
    "# ax2.set_xlabel('Percentage of dataset')\n",
    "# ax2.set_xticklabels(['0%','20%','40%', '60%', '80%', '100%'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop some unnecessary columns\n",
    "try:\n",
    "    sensors_df_akima.drop(['timestamp'], axis=1, inplace=True)\n",
    "except KeyError as e:\n",
    "    print(\"Column does not exist:  \", str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide data into three sets: train(55%), validation(25%) and test(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sensors_df_akima.copy()\n",
    "df_validation = sensors_df_akima.copy()\n",
    "df_test = sensors_df_akima.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.index <= round(len(sensors_df_akima)*0.55)]\n",
    "df_validation = df_validation[(df_validation.index > round(len(sensors_df_akima)*0.55)) & (df_validation.index <= round(len(sensors_df_akima)*0.8))]\n",
    "df_test = df_test[df_test.index > round(len(sensors_df_akima)*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of: \n",
      " train set: 121177 \n",
      " validation set: 55080 \n",
      " test set 44063\n"
     ]
    }
   ],
   "source": [
    "print('Size of: \\n train set: {} \\n validation set: {} \\n test set {}'.format(len(df_train), len(df_validation), len(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply min max scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = sensors_df_akima.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = pd.DataFrame(min_max.fit_transform(df_train), columns=col_names, index=df_train.index)\n",
    "df_validation_norm = pd.DataFrame(min_max.fit_transform(df_validation), columns=col_names, index=df_validation.index)\n",
    "df_test_norm = pd.DataFrame(min_max.fit_transform(df_test), columns=col_names, index=df_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Represent data as moving widnow in order to apply it into the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>x0_BROKEN</th>\n",
       "      <th>x0_NORMAL</th>\n",
       "      <th>x0_RECOVERING</th>\n",
       "      <th>normal_time</th>\n",
       "      <th>broken_time</th>\n",
       "      <th>recovering_time</th>\n",
       "      <th>fail_in_1_days</th>\n",
       "      <th>fail_in_3_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976786</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.792223</td>\n",
       "      <td>0.764598</td>\n",
       "      <td>0.626734</td>\n",
       "      <td>0.686154</td>\n",
       "      <td>0.726412</td>\n",
       "      <td>0.707483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134314</td>\n",
       "      <td>0.176365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.976786</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.792223</td>\n",
       "      <td>0.764598</td>\n",
       "      <td>0.626734</td>\n",
       "      <td>0.686154</td>\n",
       "      <td>0.726412</td>\n",
       "      <td>0.707483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134314</td>\n",
       "      <td>0.176365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971050</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.877907</td>\n",
       "      <td>0.797885</td>\n",
       "      <td>0.735461</td>\n",
       "      <td>0.622673</td>\n",
       "      <td>0.682154</td>\n",
       "      <td>0.728779</td>\n",
       "      <td>0.705442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.178753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.975420</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.853006</td>\n",
       "      <td>0.877907</td>\n",
       "      <td>0.784382</td>\n",
       "      <td>0.769891</td>\n",
       "      <td>0.622335</td>\n",
       "      <td>0.691077</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>0.708844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131373</td>\n",
       "      <td>0.178156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971323</td>\n",
       "      <td>0.740885</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.877907</td>\n",
       "      <td>0.794836</td>\n",
       "      <td>0.765891</td>\n",
       "      <td>0.624027</td>\n",
       "      <td>0.689539</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>0.708844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130392</td>\n",
       "      <td>0.176365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  sensor_05  \\\n",
       "0   0.976786   0.739583   0.855233   0.872093   0.792223   0.764598   \n",
       "1   0.976786   0.739583   0.855233   0.872093   0.792223   0.764598   \n",
       "2   0.971050   0.747396   0.855233   0.877907   0.797885   0.735461   \n",
       "3   0.975420   0.739583   0.853006   0.877907   0.784382   0.769891   \n",
       "4   0.971323   0.740885   0.855233   0.877907   0.794836   0.765891   \n",
       "\n",
       "   sensor_06  sensor_07  sensor_08  sensor_09  ...  sensor_49  sensor_51  \\\n",
       "0   0.626734   0.686154   0.726412   0.707483  ...   0.134314   0.176365   \n",
       "1   0.626734   0.686154   0.726412   0.707483  ...   0.134314   0.176365   \n",
       "2   0.622673   0.682154   0.728779   0.705442  ...   0.132353   0.178753   \n",
       "3   0.622335   0.691077   0.732499   0.708844  ...   0.131373   0.178156   \n",
       "4   0.624027   0.689539   0.732499   0.708844  ...   0.130392   0.176365   \n",
       "\n",
       "   x0_BROKEN  x0_NORMAL  x0_RECOVERING  normal_time  broken_time  \\\n",
       "0        0.0        1.0            0.0     0.000023          0.0   \n",
       "1        0.0        1.0            0.0     0.000047          0.0   \n",
       "2        0.0        1.0            0.0     0.000070          0.0   \n",
       "3        0.0        1.0            0.0     0.000093          0.0   \n",
       "4        0.0        1.0            0.0     0.000117          0.0   \n",
       "\n",
       "   recovering_time  fail_in_1_days  fail_in_3_days  \n",
       "0              0.0             0.0             0.0  \n",
       "1              0.0             0.0             0.0  \n",
       "2              0.0             0.0             0.0  \n",
       "3              0.0             0.0             0.0  \n",
       "4              0.0             0.0             0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm_data = df_train_norm.drop(['fail_in_1_days', 'fail_in_3_days'], axis=1)\n",
    "df_train_norm_label = df_train_norm['fail_in_1_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(sequence_len, df):\n",
    "    data_matrix = df.values\n",
    "    for i in range(0, len(df) - sequence_len):\n",
    "        yield data_matrix[i:sequence_len+i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_gen = [next(generate_sequence(sequence_len, df_train_norm_data)) for i in range(0, len(df_train_norm_data) - sequence_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_array = np.stack(seq_gen).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data into model: \n",
      " number of sequences: 121117 \n",
      " number of samples in sequence: 60 \n",
      " number of features: 56\n"
     ]
    }
   ],
   "source": [
    "seq_array_shape = seq_array.shape\n",
    "print('Input data into model: \\n number of sequences: {} \\n number of samples in sequence: {} \\n number of features: {}'.\n",
    "      format(seq_array_shape[0], seq_array_shape[1], seq_array_shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(sequence_len, df):\n",
    "    data_matrix = df.values\n",
    "    num_of_elements = data_matrix.shape[0]\n",
    "    return data_matrix[sequence_len:num_of_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = generate_label(sequence_len, df_train_norm_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = label_array.reshape(label_array.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121117, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets preserve created training and testing arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('seq_array', seq_array)\n",
    "np.save('label_array', label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building </br>\n",
    "Output layer will contain one node and sigmoid activation function as the task is binary classification. </br>\n",
    "Dropout will be applied to control overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "import keras\n",
    "import keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'binary_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = seq_array_shape[2]\n",
    "number_outcome = label_array.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(\n",
    "            input_shape=(sequence_len , number_of_features),\n",
    "            units=100,\n",
    "            return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(\n",
    "            units=50,\n",
    "            return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(\n",
    "            units=number_outcome,\n",
    "            activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 60, 100)           62800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 93,051\n",
      "Trainable params: 93,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109005 samples, validate on 12112 samples\n",
      "Epoch 1/10\n",
      " 16800/109005 [===>..........................] - ETA: 2:16 - loss: 0.0406 - acc: 0.9933 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-aed90f0d5d19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                                              \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                              \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                                              mode='auto')])\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=seq_array,\n",
    "          y=label_array,\n",
    "          epochs=10,\n",
    "          batch_size=600,\n",
    "          validation_split=0.1,\n",
    "          verbose=1,callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                             min_delta=0,\n",
    "                                                             patience=5,\n",
    "                                                             verbose=0, \n",
    "                                                             mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
